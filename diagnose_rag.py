#!/usr/bin/env python3
"""
è¯Šæ–­ RAG æ£€ç´¢é—®é¢˜çš„è„šæœ¬
æ£€æŸ¥ï¼š
1. å‘é‡å­˜å‚¨ä¸­æ˜¯å¦æœ‰ ChatGPT æ–‡æ¡£
2. BM25 ç´¢å¼•æ˜¯å¦åŒ…å«å…³é”®è¯
3. æ£€ç´¢ç»“æœæ˜¯ä»€ä¹ˆ
"""

import os
os.environ["LOG_LEVEL"] = "DEBUG"

from model_providers import LocalLLModel
from rag import LocalRAG

print("=" * 80)
print("RAG æ£€ç´¢è¯Šæ–­å·¥å…·")
print("=" * 80)

# åˆå§‹åŒ–
llm = LocalLLModel()
rag = LocalRAG(llm, data_path="./docs", use_hybrid_search=True, use_reranking=True)

print("\n1ï¸âƒ£ åˆå§‹åŒ– RAG é“¾...")
rag.init_rag_chain()

print(f"\n2ï¸âƒ£ æ£€æŸ¥æ–‡æ¡£æ•°é‡:")
print(f"   - all_documents: {len(rag.all_documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")

if rag.all_documents:
    print(f"\n3ï¸âƒ£ æ£€æŸ¥æ˜¯å¦åŒ…å« 'torch' å…³é”®è¯:")
    torch_docs = [doc for doc in rag.all_documents if 'torch' in doc.page_content.lower()]
    print(f"   - åŒ…å« 'torch' çš„æ–‡æ¡£: {len(torch_docs)} ä¸ª")
    
    if torch_docs:
        print(f"\n   ğŸ“„ ç¤ºä¾‹æ–‡æ¡£ (å‰3ä¸ª):")
        for i, doc in enumerate(torch_docs[:3]):
            print(f"\n   æ–‡æ¡£ {i+1}:")
            print(f"   æ¥æº: {doc.metadata.get('source', 'unknown')}")
            print(f"   æ ‡é¢˜: {doc.metadata.get('title', 'N/A')}")
            print(f"   é•¿åº¦: {len(doc.page_content)} å­—ç¬¦")
            preview = doc.page_content[:200].replace('\n', ' ')
            print(f"   é¢„è§ˆ: {preview}...")

print(f"\n4ï¸âƒ£ æµ‹è¯•æ£€ç´¢ 'torch':")
if rag.rag_chain:
    try:
        # æ‰‹åŠ¨æ‰§è¡Œæ£€ç´¢æ­¥éª¤ - ç›´æ¥è°ƒç”¨ retrieval_runnable
        # ä» init_rag_chain ä¸­æˆ‘ä»¬çŸ¥é“ chain çš„ç¬¬ä¸€æ­¥æ˜¯ {"context": retrieval_runnable, "question": lambda x: x}
        # æˆ‘ä»¬éœ€è¦ç›´æ¥æµ‹è¯•æ£€ç´¢å™¨
        from rag import LocalRAG
        
        # é‡æ–°è·å– vectorstore å’Œæ„å»º retriever
        vectorstore = rag.get_or_create_vectorstore()
        from retrievers import HybridRetriever
        from typing import cast
        from langchain_milvus import Milvus
        
        vectorstore = cast(Milvus, vectorstore)
        if rag.use_hybrid_search and rag.all_documents:
            retriever = HybridRetriever(
                vectorstore=vectorstore,
                documents=rag.all_documents,
                vector_weight=0.7,
                bm25_weight=0.3,
                k=10
            )
        else:
            retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
        
        docs = retriever.invoke("torch")
        
        print(f"   - æ£€ç´¢åˆ° {len(docs)} ä¸ªæ–‡æ¡£")
        
        if docs:
            print(f"\n   ğŸ“„ æ£€ç´¢ç»“æœ:")
            for i, doc in enumerate(docs):
                print(f"\n   ç»“æœ {i+1}:")
                print(f"   æ¥æº: {doc.metadata.get('source', 'unknown')}")
                print(f"   æ ‡é¢˜: {doc.metadata.get('title', 'N/A')}")
                print(f"   é•¿åº¦: {len(doc.page_content)} å­—ç¬¦")
                preview = doc.page_content[:300].replace('\n', ' ')
                print(f"   å†…å®¹: {preview}...")
        else:
            print("   âŒ æ²¡æœ‰æ£€ç´¢åˆ°ä»»ä½•æ–‡æ¡£ï¼")
    except Exception as e:
        print(f"   âŒ æ£€ç´¢æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

print(f"\n5ï¸âƒ£ æµ‹è¯•å®Œæ•´ RAG æŸ¥è¯¢:")
answer = rag.generate_answer("torch")
print(f"   ç­”æ¡ˆ: {answer}")

print("\n" + "=" * 80)
print("è¯Šæ–­å®Œæˆ")
print("=" * 80)
