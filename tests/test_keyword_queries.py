#!/usr/bin/env python3
"""æµ‹è¯•å…³é”®è¯æŸ¥è¯¢çš„æ”¹è¿›æ•ˆæœ"""

import os
os.environ["LOG_LEVEL"] = "WARNING"  # å‡å°‘æ—¥å¿—è¾“å‡º

from model_providers import LocalLLModel
from rag import LocalRAG

print("=" * 80)
print("æµ‹è¯•å…³é”®è¯æŸ¥è¯¢æ”¹è¿›")
print("=" * 80)

llm = LocalLLModel()
rag = LocalRAG(llm, data_path="./docs", use_hybrid_search=True, use_reranking=True)

print("\nåˆå§‹åŒ– RAG ç³»ç»Ÿ...")
rag.init_rag_chain()
print(f"âœ… å·²åŠ è½½ {len(rag.all_documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")

# æµ‹è¯•ä¸åŒç±»å‹çš„æŸ¥è¯¢
test_cases = [
    {
        "type": "å…³é”®è¯æŸ¥è¯¢",
        "queries": [
            "torch",
            "torch-directml",
            "Python 3.11"
        ]
    },
    {
        "type": "å®Œæ•´é—®é¢˜",
        "queries": [
            "torch-directml éœ€è¦ä»€ä¹ˆ Python ç‰ˆæœ¬ï¼Ÿ",
            "å¦‚ä½•å®‰è£… torch-directmlï¼Ÿ"
        ]
    }
]

for test_case in test_cases:
    print(f"\n{'='*80}")
    print(f"ğŸ“‹ æµ‹è¯•ç±»å‹: {test_case['type']}")
    print('='*80)
    
    for query in test_case['queries']:
        print(f"\nğŸ” æŸ¥è¯¢: {query}")
        print("-" * 80)
        try:
            answer = rag.generate_answer(query)
            print(f"ğŸ’¬ ç­”æ¡ˆ:\n{answer}")
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        print()

print("\n" + "=" * 80)
print("æµ‹è¯•å®Œæˆ")
print("=" * 80)
